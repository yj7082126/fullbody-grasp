{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"osmesa\"\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from bps_torch.bps import bps_torch\n",
    "from smplx import SMPLXLayer\n",
    "from psbody.mesh.colors import name_to_rgb\n",
    "import pyrender\n",
    "import meshplot as mp\n",
    "\n",
    "from models.cvae import gnet_model\n",
    "from models.model_utils import parms_6D2full\n",
    "from tools.objectmodel import ObjectModel\n",
    "from tools.utils import to_cpu, euler\n",
    "from tools.gnet_optim import GNetOptim as FitSmplxStatic\n",
    "from tools.meshviewer import Mesh\n",
    "\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "cfg_static = OmegaConf.load(\"configs/GNet_orig.yaml\")\n",
    "cfg_static.best_model = \"models/GNet_model.pt\"\n",
    "\n",
    "body_model = SMPLXLayer(\n",
    "    model_path=\"/data/3D_dataset/smpl_related/models/smplx\", gender='neutral', num_pca_comps=45, flat_hand_mean=True\n",
    ").to(device)\n",
    "sbj_vtemp = body_model()\n",
    "\n",
    "network_static = gnet_model(**cfg_static.network.gnet_model).eval().to(device)\n",
    "network_static.cfg = cfg_static\n",
    "network_static.load_state_dict(torch.load(cfg_static.best_model, map_location=device), strict=False)\n",
    "\n",
    "bps_torch_model = bps_torch()\n",
    "bps = torch.load(\"configs/bps.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f66d4e2a3764c9eb998acdee15fe019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(5.0663948â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x7f93ea783b50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_path = '/shared/3D/GrabFusion/data/dex-ycb-models/002_master_chef_can/textured_simple.obj'\n",
    "input_trans = [0.0,  1.6, 0.0] # rel. to root joint of smplx\n",
    "input_rot = np.deg2rad([90,0,0])\n",
    "\n",
    "transl_obj = torch.tensor([input_trans], dtype=torch.float32, device=device)\n",
    "global_orient_obj = torch.tensor([input_rot], dtype=torch.float32, device=device)\n",
    "transl_obj = sbj_vtemp.joints[0,0] +transl_obj\n",
    "\n",
    "obj_mesh = Mesh(filename=obj_path, vscale=1.0)\n",
    "obj_verts = obj_mesh.vertices\n",
    "obj_m = ObjectModel(v_template=torch.from_numpy(obj_verts)).to(device)\n",
    "obj_m.faces = obj_mesh.faces\n",
    "\n",
    "verts_obj = obj_m(transl=transl_obj, global_orient=global_orient_obj).vertices[0]\n",
    "obj_bps = bps['obj'].to(device) + transl_obj.reshape(1, 1, 3)\n",
    "bps_obj_glob = bps_torch_model.encode(x=verts_obj, feature_type=['deltas'], custom_basis=obj_bps)['deltas']\n",
    "\n",
    "batch = {\n",
    "    'transl_obj' : transl_obj,\n",
    "    'global_orient_obj' : global_orient_obj,\n",
    "    'bps_obj_glob' : bps_obj_glob,\n",
    "    'gender' : 1\n",
    "}\n",
    "fit_smplx_static = FitSmplxStatic(sbj_model=body_model, obj_model=obj_m, cfg=cfg_static, verbose=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sbj_output = body_model(transl=torch.tensor([[ 0.0,  1.25, -0.5]], device='cuda:0'))\n",
    "    verts_sbj = sbj_output.vertices[0].detach()\n",
    "\n",
    "mp_viewer = mp.plot(to_cpu(verts_sbj)-[0.0,0.75,0.0], body_model.faces, np.array([0.75,0.75,0.75]))\n",
    "mp_viewer.add_mesh(to_cpu(verts_obj)-[0.0,0.75,0.0], obj_mesh.faces, np.array([1.0,0.0,0.0]))\n",
    "mp_viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(5171)\n",
    "\n",
    "z_enc_s = torch.distributions.normal.Normal(\n",
    "    loc=torch.zeros([1, 16], requires_grad=False).to(device),\n",
    "    scale=torch.ones([1, 16], requires_grad=False).to(device)\n",
    ").rsample()\n",
    "\n",
    "dec_x = {\n",
    "    'betas' : torch.zeros([1, 1, 10], dtype=torch.float32, device=device), \n",
    "    'transl_obj' : batch['transl_obj'], \n",
    "    'bps_obj' : batch['bps_obj_glob'].norm(dim=-1),\n",
    "    'z' : z_enc_s\n",
    "}\n",
    "dec_x = torch.cat([v.reshape(1, -1).to(device) for v in dec_x.values()], dim=1)\n",
    "\n",
    "net_output = network_static.decode(dec_x)\n",
    "bparams = parms_6D2full(net_output['pose'], net_output['trans'], d62rot=True)\n",
    "net_output[f'm_params'] = bparams\n",
    "\n",
    "cnet_verts, cnet_s_verts = fit_smplx_static.get_smplx_verts(batch, {\"cnet\" : net_output})\n",
    "optim_output = fit_smplx_static.fitting(batch, {\"cnet\" : net_output})\n",
    "\n",
    "sbj_verts = to_cpu(optim_output['opt_verts'][0])\n",
    "obj_verts = to_cpu(fit_smplx_static.obj_verts[0])\n",
    "\n",
    "mp_viewer = mp.plot(sbj_verts, body_model.faces, np.array([0.75,0.75,0.75]))\n",
    "mp_viewer.add_mesh(obj_verts, obj_mesh.faces, np.array([1.0,0.0,0.0]))\n",
    "mp_viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = [0,0,0]\n",
    "trans = [0.0, 1.0, 0.0]\n",
    "z_dist = 2.0\n",
    "a_light = 0.4\n",
    "d_light = 3.0\n",
    "w, h = 512, 512\n",
    "\n",
    "# sbj_verts = to_cpu(cnet_verts[0]) - np.array([trans])\n",
    "sbj_verts = to_cpu(optim_output['opt_verts'][0]) - np.array([trans])\n",
    "obj_verts = to_cpu(fit_smplx_static.obj_verts[0]) - np.array([trans])\n",
    "sbj_opt = Mesh(vertices=sbj_verts, faces=body_model.faces, vc=[0.5,0.5,0.5])\n",
    "obj_i = Mesh(vertices=obj_verts, faces=obj_mesh.faces, vc=name_to_rgb['red'])\n",
    "obj_array = [sbj_opt, obj_i]\n",
    "\n",
    "scene = pyrender.Scene(bg_color=[0.0,0.0,0.0,1.0], ambient_light=a_light, name='scene')\n",
    "\n",
    "pc = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1.0)\n",
    "camera_pose = np.eye(4)\n",
    "camera_pose[:3, :3] = euler([0.0, 0.0, 0.0], 'xzy')\n",
    "camera_pose[:3, 3] = np.array([0.0, 0.0, z_dist])\n",
    "cam = pyrender.Node(name = 'camera', camera=pc, matrix=camera_pose)\n",
    "scene.add_node(cam)\n",
    "\n",
    "light = pyrender.light.DirectionalLight(color=np.ones(3), intensity=d_light)\n",
    "light = pyrender.Node(light=light, matrix=camera_pose)\n",
    "scene.add_node(light)\n",
    "\n",
    "for obj in obj_array:\n",
    "    obj.rot_verts(euler(angle, 'xzy'))\n",
    "    mesh = pyrender.Mesh.from_trimesh(obj)\n",
    "    scene.add(mesh)\n",
    "\n",
    "viewer = pyrender.OffscreenRenderer(w, h)\n",
    "color, depth_buffer = viewer.render(scene)\n",
    "viewer.delete()\n",
    "\n",
    "depth = depth_buffer.copy()\n",
    "mask = depth > 0\n",
    "color_image = Image.fromarray(np.concatenate([color, (mask[...,np.newaxis]*255.).astype(np.uint8)], axis=-1))\n",
    "color_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_test = LoadData(cfg_static.datasets, split_name='test')\n",
    "# batch = ds_test[0]\n",
    "# batch = {k: batch[k].unsqueeze(0).to(device) for k in ['idx', 'gender', 'sbj_vtemp', 'transl_obj', 'global_orient_obj', 'betas', 'bps_obj_glob']}\n",
    "\n",
    "# ds_dir = Path(\"/data/3D_dataset/GrabNet/data/GRAB/data/GNet_data\")\n",
    "\n",
    "# ds = np2torch(np.load(ds_dir / 'test/GNet_data.npy', allow_pickle=True))\n",
    "# frame_names = np.load(ds_dir / 'test/frame_names.npz')['frame_names']\n",
    "# sbj_info = np.load(ds_dir / 'sbj_info.npy', allow_pickle=True).item()\n",
    "\n",
    "# base_path = ds_dir.parent / 'tools/subject_meshes'\n",
    "# file_list = []\n",
    "# for sbj, sbj_dict in list(sbj_info.items()):\n",
    "#     gender = sbj_dict['gender']\n",
    "#     file_list.append(base_path / f'{gender}/{sbj}.ply')\n",
    "# sbj_vtemp = torch.from_numpy(np.asarray([Mesh(filename=file).vertices.astype(np.float32) for file in file_list]))\n",
    "# sbj_betas = torch.from_numpy(np.asarray([np.load(file=f.parent / f'{f.stem}_betas.npy').astype(np.float32) for f in file_list]))\n",
    "\n",
    "# idx = 0\n",
    "\n",
    "# frame_name = Path(frame_names[idx])\n",
    "# sequence_name, obj_name = frame_name.parts[-2], frame_name.parts[-1].split(\"_\")[0]\n",
    "# batch = {k: to_tensor(ds[k][idx], dtype=torch.float32).unsqueeze(0).to(device) for k in ['transl_obj', 'global_orient_obj', 'bps_obj_glob']}\n",
    "# batch['gender'] = sbj_dict['gender']\n",
    "\n",
    "# sbj_dict = sbj_info[sequence_name]\n",
    "# sbj_dict['betas'] = to_tensor(sbj_dict['betas'], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "# # sbj_dict['betas'] = torch.zeros([1, 1, 10], dtype=torch.float32, device=device)\n",
    "# sbj_dict['vtemp'] = to_tensor(sbj_dict['vtemp'], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "# sbj_m = female_model if sbj_dict['gender'] == \"female\" else male_model\n",
    "# sbj_m.v_template = sbj_dict['vtemp'] \n",
    "\n",
    "# obj_mesh = Mesh(filename=ds_dir.parent / f'tools/object_meshes/contact_meshes/{obj_name}.ply')\n",
    "# obj_verts = torch.from_numpy(obj_mesh.vertices)\n",
    "# obj_m = ObjectModel(v_template=obj_verts).to(device)\n",
    "# obj_m.faces = obj_mesh.faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import smplx\n",
    "# from tools.utils import parse_npz, aa2rotmat, rotmat2aa, rotate, rotmul, euler, prepare_params, params2torch\n",
    "\n",
    "# bps = torch.load(\"configs/bps.pt\")\n",
    "# all_seqs = [x for x in ds_dir.parent.glob(\"grab/*/*.npz\") if x.stem.split(\"_\")[0] in ['mug', 'binoculars']]\n",
    "# sequence = all_seqs[0]\n",
    "# seq_data = parse_npz(sequence)\n",
    "\n",
    "# motion_obj = params2torch(prepare_params(seq_data.object.params, frame_mask, rel_offset))\n",
    "\n",
    "# R = torch.tensor([[1., 0., 0.], [0., 0., -1.], [0., 1., 0.]]).reshape(1, 3, 3).transpose(1,2)\n",
    "# root_offset = smplx.lbs.vertices2joints(sbj_m.J_regressor, sbj_m.v_template.view(1, -1, 3))[0, 0]\n",
    "\n",
    "\n",
    "# trans_obj_rel = rotate(motion_obj['transl'], R)\n",
    "# global_orient_obj_rotmat = aa2rotmat(motion_obj['global_orient'])\n",
    "# global_orient_obj_rel = rotmul(global_orient_obj_rotmat, R.transpose(1, 2))\n",
    "# transl_obj = to_tensor(trans_obj_rel)\n",
    "# global_orient_obj = rotmat2aa(to_tensor(global_orient_obj_rel).squeeze()).squeeze()\n",
    "\n",
    "# verts_obj = obj_m(**motion_obj).vertices\n",
    "# obj_bps = bps['obj'] + motion_obj['transl'].reshape(1, 1, 3)\n",
    "# bps_obj = bps_torch.encode(x=verts_obj, feature_type=['deltas'], custom_basis=obj_bps)['deltas']\n",
    "\n",
    "# ds_dir = Path(\"/data/3D_dataset/GrabNet/data/GRAB/data/GNet_data\")\n",
    "# ds = np2torch(np.load(ds_dir / 'test/GNet_data.npy', allow_pickle=True))\n",
    "# frame_names = np.load(ds_dir / 'test/frame_names.npz')['frame_names']\n",
    "# bps = torch.load(\"configs/bps.pt\")\n",
    "\n",
    "# # idx = 400\n",
    "# obj_path = 'mug'\n",
    "# obj_name = Path(frame_names[idx]).parts[-1].split(\"_\")[0]\n",
    "# # transl_obj = to_tensor(ds['transl_obj'][idx], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "# transl_obj = torch.tensor([[0.0, 1.0, 0.0]], dtype=torch.float32, device=device)\n",
    "# # global_orient_obj = to_tensor(ds['global_orient_obj'][idx], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "# global_orient_obj = torch.tensor([np.deg2rad([26.009653, -108.771225, -122.78726])], dtype=torch.float32, device=device)\n",
    "\n",
    "# obj_mesh = Mesh(filename=ds_dir.parent / f'tools/object_meshes/contact_meshes/{obj_name}.ply')\n",
    "# obj_m = ObjectModel(v_template=torch.from_numpy(obj_mesh.vertices)).to(device)\n",
    "# obj_m.faces = obj_mesh.faces\n",
    "\n",
    "# verts_obj = obj_m(transl=transl_obj, global_orient=global_orient_obj).vertices[0]\n",
    "# obj_bps = bps['obj'].to(device) + transl_obj.reshape(1, 1, 3)\n",
    "# bps_obj_glob = bps_torch.encode(x=verts_obj, feature_type=['deltas'], custom_basis=obj_bps)['deltas']\n",
    "\n",
    "# batch = {\n",
    "#     'transl_obj' : transl_obj,\n",
    "#     'global_orient_obj' : global_orient_obj,\n",
    "#     'bps_obj_glob' : bps_obj_glob,\n",
    "#     'gender' : 1\n",
    "# }\n",
    "# fit_smplx_static = FitSmplxStatic(sbj_model=body_model, obj_model=obj_m, cfg=cfg_static, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# obj_path = '/shared/3D/GrabFusion/data/dex-ycb-models/002_master_chef_can/textured_simple.obj'\n",
    "# input_trans = [0.0,  1.6, 0.0]\n",
    "# input_rot = np.deg2rad([90,0,0])\n",
    "\n",
    "# time_array = []\n",
    "# for _ in range(10):\n",
    "#     # obj_verts, obj_faces, obj_img = pipeline3d.get_obj_verts(obj_path, obj_rot=obj_rot, obj_trans=obj_trans, re_scale=obj_scale)\n",
    "#     stime = time.time()\n",
    "#     transl_obj = torch.tensor([input_trans], dtype=torch.float32, device=device)\n",
    "#     global_orient_obj = torch.tensor([input_rot], dtype=torch.float32, device=device)\n",
    "\n",
    "#     obj_mesh = Mesh(filename=obj_path, vscale=1.0)\n",
    "#     obj_verts = obj_mesh.vertices\n",
    "#     obj_m = ObjectModel(v_template=torch.from_numpy(obj_verts)).to(device)\n",
    "#     obj_m.faces = obj_mesh.faces\n",
    "\n",
    "#     verts_obj = obj_m(transl=transl_obj, global_orient=global_orient_obj).vertices[0]\n",
    "#     obj_bps = bps['obj'].to(device) + transl_obj.reshape(1, 1, 3)\n",
    "#     bps_obj_glob = bps_torch.encode(x=verts_obj, feature_type=['deltas'], custom_basis=obj_bps)['deltas']\n",
    "\n",
    "#     batch = {\n",
    "#         'transl_obj' : transl_obj,\n",
    "#         'global_orient_obj' : global_orient_obj,\n",
    "#         'bps_obj_glob' : bps_obj_glob,\n",
    "#         'gender' : 1\n",
    "#     }\n",
    "#     fit_smplx_static = FitSmplxStatic(sbj_model=body_model, obj_model=obj_m, cfg=cfg_static, verbose=True)\n",
    "\n",
    "#     torch.manual_seed(5171)\n",
    "\n",
    "#     z_enc_s = torch.distributions.normal.Normal(\n",
    "#         loc=torch.zeros([1, 16], requires_grad=False).to(device),\n",
    "#         scale=torch.ones([1, 16], requires_grad=False).to(device)\n",
    "#     ).rsample()\n",
    "\n",
    "#     dec_x = {\n",
    "#         'betas' : torch.zeros([1, 1, 10], dtype=torch.float32, device=device), \n",
    "#         'transl_obj' : batch['transl_obj'], \n",
    "#         'bps_obj' : batch['bps_obj_glob'].norm(dim=-1),\n",
    "#         'z' : z_enc_s\n",
    "#     }\n",
    "#     dec_x = torch.cat([v.reshape(1, -1).to(device) for v in dec_x.values()], dim=1)\n",
    "\n",
    "#     net_output = network_static.decode(dec_x)\n",
    "#     bparams = parms_6D2full(net_output['pose'], net_output['trans'], d62rot=True)\n",
    "#     net_output[f'm_params'] = bparams\n",
    "\n",
    "#     cnet_verts, cnet_s_verts = fit_smplx_static.get_smplx_verts(batch, {\"cnet\" : net_output})\n",
    "#     optim_output = fit_smplx_static.fitting(batch, {\"cnet\" : net_output})\n",
    "\n",
    "#     sbj_verts = to_cpu(optim_output['opt_verts'][0])\n",
    "#     obj_verts = to_cpu(fit_smplx_static.obj_verts[0])\n",
    "\n",
    "#     time_array.append(time.time() - stime)\n",
    "\n",
    "# np.array(time_array).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
