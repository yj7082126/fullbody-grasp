{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"osmesa\"\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import smplx, mano, trimesh\n",
    "from pytorch3d.structures import Meshes\n",
    "from psbody.mesh import MeshViewers, Mesh\n",
    "from psbody.mesh.colors import name_to_rgb\n",
    "import meshplot as mp\n",
    "\n",
    "from pct.two_stage import concatMap, Point2Hand\n",
    "from transformers_model.motion_model import pretrain_actor_rel\n",
    "from tools.objectmodel import ObjectModel\n",
    "# from tools.meshviewer import Mesh\n",
    "from tools.utils import to_cpu, to_tensor, trans_global2loc_rh_wrist\n",
    "from tools.utils import aa2rotmat, rotmat2aa, rotmat2d6, d62rotmat, get_relation_map_new\n",
    "from tools.model_utils import parms_6D2full_rh, full2bone_pretrain\n",
    "from tools.optim_union import CoopOptim\n",
    "\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3407)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "rhand_model = mano.load(\n",
    "    model_path='/data/3D_dataset/smpl_related/models/mano',\n",
    "    model_type='mano', num_pca_comps=45,\n",
    "    use_pca=False, batch_size=1,\n",
    "    flat_hand_mean=True).to(device)\n",
    "\n",
    "body_model = smplx.SMPLXLayer(\n",
    "    model_path='/data/3D_dataset/smpl_related/models/smplx',\n",
    "    gender='male', num_pca_comps=45,\n",
    "    use_pca=False, batch_size=1,\n",
    "    flat_hand_mean=True).to(device)\n",
    "\n",
    "object_model = ObjectModel().to(device)\n",
    "\n",
    "# Create the network\n",
    "relation_map = get_relation_map_new()\n",
    "\n",
    "contact_cfg = OmegaConf.load(\"../model/Hnet/hand2contact.yaml\")\n",
    "contact_network = concatMap(**contact_cfg.network.coop_model).eval().to(device)\n",
    "contact_network.load_state_dict(torch.load(\"../model/Hnet/hand2contact_pt.pt\", map_location='cpu'))\n",
    "\n",
    "hand_cfg = OmegaConf.load(\"../model/Hnet/contact2hand.yaml\")\n",
    "hand_network = Point2Hand(**hand_cfg.network.coop_model).eval().to(device)\n",
    "hand_network.load_state_dict(torch.load(\"../model/Hnet/contact2hand_pt.pt\", map_location='cpu'))\n",
    "\n",
    "body_cfg = OmegaConf.load(\"../model/Bnet/body_net.yaml\")\n",
    "body_network = pretrain_actor_rel(relation_map=relation_map, **body_cfg.network.coop_model).to(device)\n",
    "body_network.load_state_dict(torch.load(\"../model/Bnet/body_net.pt\", map_location='cpu'))\n",
    "\n",
    "rh_ids_sampled = torch.from_numpy(np.load('./consts/valid_rh_idx_99.npy'))\n",
    "rh_verts_ids = to_tensor(np.load('./consts/MANO_SMPLX_vertex_ids.pkl',allow_pickle=True)['right_hand'], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data.dataloader_union import LoadData\n",
    "# ds_test = LoadData(body_cfg.datasets, split_name='test')\n",
    "# batch = ds_test[0]\n",
    "# for k,v in batch.items():\n",
    "#     batch[k] = v.unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_path = \"/shared/3D/GrabFusion/data/dex-ycb-models/025_mug/textured_simple.obj\"\n",
    "obj_mesh = trimesh.load(obj_path)\n",
    "obj_verts = torch.from_numpy(obj_mesh.vertices)\n",
    "obj_m = ObjectModel(v_template=obj_verts).to(device)\n",
    "\n",
    "body_fit_smplx = CoopOptim(\n",
    "    sbj_model=body_model, rh_model=rhand_model, obj_model=obj_m,\n",
    "    cfg=body_cfg, device=device, verbose=True\n",
    ")\n",
    "\n",
    "# grnd_mesh, cage, axis_l = get_ground()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = 0.4, -0.4, 1.4\n",
    "\n",
    "# transl = torch.tensor([[-0.0255,  1.3412, -0.5916]], dtype=torch.float32, device=device)\n",
    "transl_obj = torch.tensor([[y, z, x]], dtype=torch.float32, device=device)\n",
    "# global_orient_obj = torch.tensor([[1.1428, 1.3750, 1.4559]], device=device)\n",
    "global_orient_obj = torch.tensor([[90.0, 0.0, 0.0]], device=device)\n",
    "# global_orient_obj_RH = torch.tensor([[-0.1865,  0.1269, -4.4412]], device=device)\n",
    "global_orient_obj_RH = torch.tensor([[0.0, 0.0, 0.0]], device=device)\n",
    "\n",
    "# batch_ = batch.copy()\n",
    "# batch_['transl_obj'][0] = torch.tensor([y, z, x])\n",
    "\n",
    "r = math.atan(y/x) if x >= 0 else math.pi + math.atan(y/x)\n",
    "reserved_r = - r if x >= 0 else 2 * math.pi - r\n",
    "rotmat = aa2rotmat(global_orient_obj_RH)\n",
    "new_rotmat = torch.matmul(\n",
    "    rotmat,\n",
    "    torch.Tensor([\n",
    "        [math.cos(r),-math.sin(r),0],\n",
    "        [math.sin(r),math.cos(r),0],\n",
    "        [0,0,1]\n",
    "    ]).to(torch.float32).to(device)\n",
    ").reshape(-1,3,3)\n",
    "# batch_['global_orient_obj_RH'] = rotmat2aa(new_rotmat)\n",
    "\n",
    "obj_verts = obj_m(transl=torch.zeros((1,3), device=device), global_orient=new_rotmat, pose2rot=False).vertices[0]\n",
    "centroid = torch.mean(obj_verts, dim=0) # bs , N\n",
    "pc_center = obj_verts - centroid\n",
    "\n",
    "mesh = Meshes(verts=pc_center[None,:], faces=torch.from_numpy(obj_mesh.faces[None,:].astype(np.int64)).to(device))\n",
    "normal = mesh.verts_normals_packed().view(-1, 3)\n",
    "simple_vertices_ids = torch.from_numpy(np.random.choice(obj_verts.shape[0], 2048, replace=False))\n",
    "input_points = pc_center[simple_vertices_ids].unsqueeze(0).to(device)\n",
    "input_normal = normal[simple_vertices_ids].unsqueeze(0).to(device)\n",
    "input_height = ((torch.Tensor([z]).to(device) - centroid[2]) / 2).unsqueeze(0).to(device)\n",
    "# batch_['verts'] = input_points\n",
    "\n",
    "obj_verts = obj_m(transl=transl_obj, global_orient=global_orient_obj).vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.manual_seed(3407)\n",
    "    torch.cuda.empty_cache()   \n",
    "    \n",
    "    contact_map = contact_network.infer(\n",
    "        points=input_points,\n",
    "        normal=input_normal,\n",
    "        obj_height=input_height\n",
    "    )['contact_map']\n",
    "    pre_map = torch.softmax(contact_map,dim=-1)\n",
    "    pre_map[:,0] -= 0.2\n",
    "    pre_map = pre_map.argmax(-1).view(-1, 2048).long()\n",
    "    # batch_['contact_map_obj'] = pre_map\n",
    "\n",
    "    net_output = hand_network(\n",
    "        # betas=batch['betas_rh'],\n",
    "        betas=torch.zeros((1,10), dtype=torch.float32, device=device),\n",
    "        contact_map=pre_map,\n",
    "        points=input_points,\n",
    "        normal=input_normal,\n",
    "        obj_height=input_height\n",
    "    )\n",
    "    pose, trans = net_output['pose'], net_output['trans']\n",
    "    cnet_params = parms_6D2full_rh(pose, trans, d62rot=True)\n",
    "    pose_aa = rotmat2aa(cnet_params['fullpose_rotmat']).view(1, -1)\n",
    "    cnet_params['hand_pose'], cnet_params['global_orient'] = pose_aa[:,3:], pose_aa[:,:3]\n",
    "    cnet_params['transl'] += centroid\n",
    "    # rhand_model.v_template = batch['sbj_vtemp_rh'].to(device)\n",
    "\n",
    "mp_viewer = mp.plot(to_cpu(rhand_model(**cnet_params).vertices[0]), rhand_model.faces, name_to_rgb['gray'])\n",
    "mp_viewer.add_mesh(to_cpu(pc_center), obj_mesh.faces, name_to_rgb['red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    net_output = body_network(\n",
    "        # betas=batch['betas_body'][:,0,:],\n",
    "        betas=torch.zeros((1,10), dtype=torch.float32, device=device),\n",
    "        wrist_transl=transl_obj,\n",
    "        gender=torch.tensor([[0]], dtype=torch.long, device=device),\n",
    "        # body_pose=torch.cat([\n",
    "        #     batch['fullpose_rotmat'][:,:21,:2,:],\n",
    "        #     batch['fullpose_rotmat'][:,25:40,:2,:]\n",
    "        # ],dim=1).view(1,-1,6),\n",
    "        body_pose=rotmat2d6(aa2rotmat(torch.zeros((1,3), device=device))).unsqueeze(1).repeat(1,36,1),\n",
    "        mask_ids = torch.tensor([[0] * 36 + [1]], dtype=torch.float32, device=device)\n",
    "    )\n",
    "    pose, trans = net_output['pose'], net_output['transl']\n",
    "\n",
    "    pose = d62rotmat(pose).view(1,-1,9).view(1,-1,3,3)\n",
    "    trans = torch.cat([torch.zeros(1,1).to(device), trans, torch.zeros(1,1).to(device)],dim=-1)\n",
    "    # trans\n",
    "    \n",
    "    # bparams = parms_6D2full_addrh_pretrain(pose, trans, batch['fullpose_rotmat'])\n",
    "    pre_rh_pose, post_rh_pose = pose[:, :21], pose[:, 21:]\n",
    "    rh_global_orient_rotmat, rh_pose = cnet_params['fullpose_rotmat'][:, 0:1], cnet_params['fullpose_rotmat'][:, 1:]\n",
    "    rh_rel_orient_rotmat = trans_global2loc_rh_wrist(rh_global_orient_rotmat,pre_rh_pose)\n",
    "    union_pose = torch.cat([pre_rh_pose,rh_rel_orient_rotmat,post_rh_pose,rh_pose],dim=1).reshape([1, -1, 3, 3])\n",
    "    \n",
    "    bparams = full2bone_pretrain(union_pose,trans)\n",
    "    bparams['fullpose_rotmat'] = union_pose\n",
    "    body_net_output = body_model(**bparams)\n",
    "    body_net_params = {\n",
    "        \"m_verts_full\" : body_net_output.vertices,\n",
    "        \"m_joints_full\" : body_net_output.joints,\n",
    "        \"m_params\" : bparams\n",
    "    }\n",
    "\n",
    "mp_viewer = mp.plot(to_cpu(body_net_output.vertices[0]), body_model.faces, name_to_rgb['gray'])\n",
    "mp_viewer.add_mesh(to_cpu(obj_verts[0]), obj_mesh.faces, name_to_rgb['red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_output = body_fit_smplx.fitting(\n",
    "    # batch_,\n",
    "    {\n",
    "        'verts' : input_points,\n",
    "        'contact_map_obj' : pre_map,\n",
    "        'transl_obj' : transl_obj,\n",
    "        'gender' : torch.tensor([0], dtype=torch.long, device=device),\n",
    "        'transl' : trans[0],\n",
    "        'transl_obj_RH' : torch.zeros((1,3), device=device),\n",
    "        'global_orient_obj_RH' : rotmat2aa(new_rotmat)\n",
    "    }, \n",
    "    {\"cnet\" : {'params' : cnet_params}}, \n",
    "    {\"cnet\" : body_net_params}, \n",
    "    obj_mesh.faces, \n",
    "    reserved_r\n",
    ")\n",
    "\n",
    "mp_viewer = mp.plot(to_cpu(optim_output['opt_verts'][0]), body_model.faces, name_to_rgb['gray'])\n",
    "mp_viewer.add_mesh(to_cpu(obj_verts[0]), obj_mesh.faces, name_to_rgb['red'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
